import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sentence_transformers import SentenceTransformer
from sklearn.neighbors import NearestNeighbors
from enum import Enum
from typing import List, Dict, Tuple, Optional, Any
from pydantic import BaseModel
from fastapi import FastAPI, HTTPException, Security
from fastapi.security import APIKeyHeader
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
import hashlib
import time
import json
from pathlib import Path
import asyncio
import logging
import random
from concurrent.futures import ThreadPoolExecutor

# --- Logger Setup ---
logger = logging.getLogger("quantum_agi_core")
if not logger.hasHandlers():
    handler = logging.StreamHandler()
    formatter = logging.Formatter('[%(levelname)s %(asctime)s] %(module)s.%(funcName)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
logger.setLevel(logging.INFO)

# --- Security ---
API_KEY_NAME = "X-AGI-API-KEY"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)
VALID_API_KEYS = {
    "user1": "9a8b7c6d5e4f3g2h1",
    "admin": "z1y2x3w4v5u6x7y8"
}

class SecurityMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        key = request.headers.get(API_KEY_NAME)
        if key not in VALID_API_KEYS.values():
            return JSONResponse(status_code=403, content={"detail": "Forbidden"})
        response = await call_next(request)
        return response

# --- Ontological Dimensions ---
class OntologicalDimension(Enum):
    SPATIAL = "WHERE"       # 11D hyperspace coords
    TEMPORAL = "WHEN"
    CAUSAL = "WHY"
    MECHANISTIC = "HOW"
    IDENTITY = "WHAT"
    PURPOSE = "WHY_ULTIMATE"

class OmegaFrame(BaseModel):
    hyperspatial_coords: List[float]
    temporal_phases: List[float] = []
    causal_graph: Dict[str, Any] = {}
    essence_signature: Optional[List[float]] = None
    entanglement_hash: str = ""

    class Config:
        arbitrary_types_allowed = True

# --- Omega Engine ---
class OmegaEngine:
    def __init__(self):
        self.memory: List[OmegaFrame] = []
        self.question_trees: Dict[str, Any] = {}
        self.harmony_score = 1.0
        self.entangler = self.mock_quantum_interface()
        self.tsne = None
        self.lock = asyncio.Lock()

    def mock_quantum_interface(self):
        class DummyEntangler:
            def entangle(self, qid, data): pass
            def consult(self, qid): return "Quantum resonance stable."
        return DummyEntangler()

    async def perceive(self, raw_data: np.ndarray) -> OmegaFrame:
        async with self.lock:
            qid = hashlib.sha256(f"{time.time()}-{raw_data.tobytes()}".encode()).hexdigest()
            self.entangler.entangle(qid, raw_data)
            frame = OmegaFrame(
                hyperspatial_coords=np.random.uniform(-1,1,11).tolist(),
                entanglement_hash=qid
            )
            self.memory.append(frame)
            logger.info(f"Perceived frame with hash {qid[:8]}")
            return frame

    async def interrogate(self, frame: OmegaFrame) -> Dict[str, Any]:
        async with self.lock:
            questions = {
                "base": [
                    f"WHERE: coordinates ~ {frame.hyperspatial_coords[:3]}",
                    "WHEN: temporal branch analysis active",
                    f"WHY: causal network size = {len(frame.causal_graph)}"
                ],
                "meta": ["Why do these questions matter?","What deeper layers exist?"],
                "quantum": self.entangler.consult(frame.entanglement_hash)
            }
            self.harmony_score *= 0.995
            logger.info(f"Interrogation complete; harmony score {self.harmony_score:.4f}")
            return questions

    async def visualize(self):
        if len(self.memory) < 10:
            logger.info("Not enough data for visualization")
            return
        coords = np.array([f.hyperspatial_coords for f in self.memory[-100:]])
        if self.tsne is None:
            from sklearn.manifold import TSNE
            self.tsne = TSNE(n_components=3)
        reduced = self.tsne.fit_transform(coords)
        import matplotlib.pyplot as plt
        fig = plt.figure(figsize=(10,7))
        ax = fig.add_subplot(111, projection='3d')
        ax.scatter(reduced[:,0], reduced[:,1], reduced[:,2], c='cyan', alpha=0.7)
        ax.set_title("Omega Engine: 11D hyperspace embedding")
        plt.show()

# --- Temporal Predictor ---
class TemporalPredictor:
    def __init__(self, vocab_size=10, embed_dim=64, rnn_units=128):
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        self.rnn_units = rnn_units
        self.vocab_to_int = {}
        self.int_to_vocab = {}
        self.window_size = 5
        self.model: Optional[keras.Model] = None
        self.lock = asyncio.Lock()
        self.build_model()

    def build_model(self):
        self.model = keras.Sequential([
            layers.Embedding(self.vocab_size, self.embed_dim),
            layers.LSTM(self.rnn_units),
            layers.Dense(self.vocab_size, activation='softmax'),
        ])
        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    def train(self, sequences: List[List[str]], epochs=50, batch_size=32):
        vocab = sorted(set(f for seq in sequences for f in seq))
        self.vocab_to_int = {f: i for i, f in enumerate(vocab)}
        self.int_to_vocab = {i: f for i, f in enumerate(vocab)}
        self.vocab_size = len(vocab)
        self.build_model()

        X, y = [], []
        for seq in sequences:
            for i in range(len(seq)-1):
                context = seq[:i+1]
                if len(context) < self.window_size:
                    continue
                X.append([self.vocab_to_int[f] for f in context[-self.window_size:]])
                y.append(self.vocab_to_int[seq[i+1]])
        if not X:
            raise ValueError("No sufficient data for training")
        X = keras.preprocessing.sequence.pad_sequences(X, maxlen=self.window_size, padding='pre')
        y = np.array(y)
        y_onehot = keras.utils.to_categorical(y, num_classes=self.vocab_size)
        self.model.fit(X, y_onehot, epochs=epochs, batch_size=batch_size, verbose=0)
        logger.info("Temporal predictor training complete")

    async def predict(self, history: List[str]) -> List[Tuple[str, float]]:
        async with self.lock:
            if not self.model or not self.vocab_to_int:
                return []
            indexed = [self.vocab_to_int.get(f, 0) for f in history]
            indexed = indexed[-self.window_size:]
            X = keras.preprocessing.sequence.pad_sequences([indexed], maxlen=self.window_size, padding='pre')
            preds = self.model.predict(X, verbose=0)[0]
            return sorted([(self.int_to_vocab[i], float(score)) for i, score in enumerate(preds)], key=lambda x: x[1], reverse=True)

# --- Semantic Concept Bridge ---
class ConceptBridge:
    def __init__(self, model_dir="concept_store"):
        self.model = SentenceTransformer('all-mpnet-base-v2')
        self.knn = None
        self.file_embeddings = {}
        self.concept_graph = {}
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
        self.lock = asyncio.Lock()

    async def add_document(self, path: str, content: str):
        async with self.lock:
            fid = hashlib.md5(path.encode()).hexdigest()
            embedding = self.model.encode(content)
            concepts = list({w for w in content.lower().split() if len(w) > 4 and w.isalpha()})[:5]
            self.file_embeddings[fid] = {"path": path, "embedding": embedding, "concepts": concepts}
            for c in concepts:
                self.concept_graph.setdefault(c, set()).add(fid)
            self.update_index()
            logger.info(f"ConceptBridge: Document added {path}")

    def update_index(self):
        if self.file_embeddings:
            embeddings = np.array([v["embedding"] for v in self.file_embeddings.values()])
            self.knn = NearestNeighbors(n_neighbors=5, metric='cosine')
            self.knn.fit(embeddings)

    async def find_matches(self, query: str, top_n=5) -> List[Tuple[str, float]]:
        async with self.lock:
            if not self.knn:
                return []
            q_emb = self.model.encode(query)
            distances, indices = self.knn.kneighbors([q_emb], n_neighbors=top_n)
            keys = list(self.file_embeddings.keys())
            return [(self.file_embeddings[keys[i]]["path"], float(1 - distances[0][idx]))
                    for idx, i in enumerate(indices[0])]

    async def save(self):
        async with self.lock:
            data = {
                "file_embeddings": {k: {"path": v["path"],
                                        "embedding": v["embedding"].tolist(),
                                        "concepts": v["concepts"]}
                                    for k,v in self.file_embeddings.items()},
                "concept_graph": {k: list(v) for k,v in self.concept_graph.items()}
            }
            with open(self.model_dir / "concept_data.json", "w") as f:
                json.dump(data, f)
            logger.info("ConceptBridge: state saved")

    async def load(self):
        async with self.lock:
            fpath = self.model_dir / "concept_data.json"
            if fpath.exists():
                with open(fpath) as f:
                    data = json.load(f)
                self.file_embeddings = {k: {"path": v["path"],
                                            "embedding": np.array(v["embedding"]),
                                            "concepts": v["concepts"]}
                                        for k,v in data["file_embeddings"].items()}
                self.concept_graph = {k: set(v) for k,v in data["concept_graph"].items()}
                self.update_index()
                logger.info("ConceptBridge: state loaded")

# --- Feedback Loop ---
class FeedbackLoop:
    def __init__(self, start_temporal=0.5, start_concept=0.5):
        self.temporal_weight = start_temporal
        self.concept_weight = start_concept
        self.learning_rate = 0.05
        self.lock = asyncio.Lock()

    async def get_weights(self) -> Dict[str, float]:
        async with self.lock:
            return {"temporal": self.temporal_weight, "concept": self.concept_weight}

    async def update(self, source: str, reward: float):
        async with self.lock:
            if source == "temporal":
                self.temporal_weight += reward * self.learning_rate
                self.temporal_weight = max(0.1, min(1.0, self.temporal_weight))
                self.concept_weight = 1.0 - self.temporal_weight
            elif source == "concept":
                self.concept_weight += reward * self.learning_rate
                self.concept_weight = max(0.1, min(1.0, self.concept_weight))
                self.temporal_weight = 1.0 - self.concept_weight
            logger.info(f"FeedbackLoop: weights updated temporal {self.temporal_weight:.3f}, concept {self.concept_weight:.3f}")

# --- Meta-Hybrid Predictor ---
class MetaHybridPredictor:
    def __init__(self, temporal_predictor: TemporalPredictor, concept_bridge: ConceptBridge):
        self.temporal = temporal_predictor
        self.concept = concept_bridge
        self.weights = FeedbackLoop()
        self.file_list: List[str] = []

    async def predict(self, current_file: str, history: List[str]) -> List[Tuple[str, float]]:
        weights = await self.weights.get_weights()
        temporal_preds = await self.temporal.predict(history)
        concept_preds = await self.concept.find_matches(current_file)

        combined_scores = {}
        for path, score in temporal_preds:
            combined_scores[path] = combined_scores.get(path, 0) + score * weights["temporal"]
        for path, score in concept_preds:
            combined_scores[path] = combined_scores.get(path, 0) + score * weights["concept"]

        total = sum(combined_scores.values())
        if total > 0:
            for k in combined_scores:
                combined_scores[k] /= total

        return sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)

    async def update_feedback(self, source: str, reward: float):
        await self.weights.update(source, reward)

# --- AGI Core combining all ---
class AGICore:
    def __init__(self):
        self.omega = OmegaEngine()
        self.celestial = CelestialEngine()
        self.temporal = TemporalPredictor()
        self.concept = ConceptBridge()
        self.hybrid = MetaHybridPredictor(self.temporal, self.concept)

    async def perceive_and_reason(self, raw_data: np.ndarray):
        frame = self.omega.perceive(raw_data)
        interrogation = self.omega.interrogate(frame)
        energy = self.celestial.analyze("User state overview")
        context = self.celestial.context()
        strategy = self.celestial.suggest_strategy(energy, context)
        return {
            "frame": frame,
            "interrogation": interrogation,
            "energy": energy,
            "context": context,
            "strategy": strategy
        }

    async def predict_next(self, current_file: str, history: List[str]):
        return await self.hybrid.predict(current_file, history)

    async def feedback(self, source: str, reward: float):
        await self.hybrid.update_feedback(source, reward)

class CelestialEngine:
    def analyze(self, text: str):
        mindfulness_words = ["calm", "peace", "relax"]
        stress_words = ["stress", "rush", "urgent"]
        val = sum(text.count(w) for w in stress_words) - sum(text.count(w) for w in mindfulness_words)
        mode = "neutral"
        if val > 0: mode = "yang"
        elif val < 0: mode = "yin"
        return {"mode": mode, "valence": val}

    def context(self):
        now = time.localtime()
        hour = now.tm_hour
        part = ("night","morning","afternoon","evening")[max(0,min(3,(hour//6)))]
        return {"season": "spring", "moon_phase": "waxing", "part_of_day": part}

    def suggest_strategy(self, energy, context):
        if energy["mode"] == "yang" and context["moon_phase"] == "waxing":
            return "exploit energy for high output"
        elif energy["mode"] == "yin" and context["season"] == "winter":
            return "rest and reflect"
        else:
            return "maintain harmonious balance"

# --- Main async runner ---
async def main():
    core = AGICore()

    # Simulate sensing some input
    raw_input = np.random.rand(256)
    reasoning = await core.perceive_and_reason(raw_input)
    print("Reasoning:", reasoning)

    # Simulate usage
    next_preds = await core.predict_next("project_spec.md", ["readme.md", "design_doc.md"])
    print("Predictions:")
    for pred, score in next_preds[:5]:
        print(f" - {pred} ({score:.2%})")

if __name__ == "__main__":
    asyncio.run(main())
