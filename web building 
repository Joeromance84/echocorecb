import os
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Optional
import git
import subprocess
from pathlib import Path

class AGIDevelopmentMatrix:
    def __init__(self, config: Dict):
        self.bulk_memory_root = Path(config['bulk_memory_path'])
        self.github_token = config.get('github_token')
        self.knowledge_repos = config['tracked_repos']
        self.app_factory_dir = self.bulk_memory_root / "app_factory"
        self.knowledge_db = self.bulk_memory_root / "knowledge_db"
        self._init_directories()
        
        # State tracking
        self.active_projects = {}
        self.capability_index = self._load_capability_index()
        self.system_health = {
            'last_sync': None,
            'memory_usage': None,
            'component_status': {}
        }

    def _init_directories(self):
        """Ensure required directory structure exists"""
        self.app_factory_dir.mkdir(exist_ok=True)
        self.knowledge_db.mkdir(exist_ok=True)
        (self.knowledge_db / "code").mkdir(exist_ok=True)
        (self.knowledge_db / "papers").mkdir(exist_ok=True)
        (self.knowledge_db / "models").mkdir(exist_ok=True)

    def _load_capability_index(self) -> Dict:
        """Load or create capability tracking index"""
        index_file = self.knowledge_db / "capability_index.json"
        if index_file.exists():
            with open(index_file, 'r') as f:
                return json.load(f)
        return {"capabilities": {}, "last_updated": None}

    def sync_knowledge_repos(self) -> Dict:
        """Synchronize all tracked GitHub repositories"""
        sync_report = {"updated": [], "failed": [], "new_capabilities": []}
        
        for repo_url in self.knowledge_repos:
            try:
                repo_name = repo_url.split('/')[-1].replace('.git', '')
                repo_dir = self.knowledge_db / "code" / repo_name
                
                if repo_dir.exists():
                    repo = git.Repo(repo_dir)
                    origin = repo.remotes.origin
                    origin.pull()
                    changes = repo.git.diff('HEAD~1')
                else:
                    repo = git.Repo.clone_from(repo_url, repo_dir)
                    changes = "Initial clone"
                
                # Analyze for new capabilities
                capability_report = self._analyze_repo_capabilities(repo_dir)
                if capability_report['new_capabilities']:
                    sync_report['new_capabilities'].extend(capability_report['new_capabilities'])
                
                sync_report['updated'].append({
                    'repo': repo_name,
                    'changes': changes,
                    'capabilities': capability_report
                })
                
            except Exception as e:
                sync_report['failed'].append({
                    'repo': repo_url,
                    'error': str(e)
                })
        
        self.system_health['last_sync'] = datetime.now().isoformat()
        return sync_report

    def _analyze_repo_capabilities(self, repo_path: Path) -> Dict:
        """Analyze repository for new AGI capabilities"""
        analysis = {"new_capabilities": []}
        
        # Check for architecture files
        arch_files = list(repo_path.glob('*architecture*.md')) + \
                    list(repo_path.glob('*design*.md'))
        
        # Check for implementation files
        impl_files = list(repo_path.glob('**/*.py')) + \
                    list(repo_path.glob('**/*.js'))
        
        # Simple capability detection (would be enhanced in production)
        for file in arch_files + impl_files:
            content = file.read_text()
            if 'neural' in content.lower() and 'network' in content.lower():
                if 'neural_network' not in self.capability_index['capabilities']:
                    analysis['new_capabilities'].append('neural_network')
                    self.capability_index['capabilities']['neural_network'] = {
                        'source': str(file),
                        'first_detected': datetime.now().isoformat()
                    }
            
            if 'reinforcement' in content.lower() and 'learning' in content.lower():
                if 'reinforcement_learning' not in self.capability_index['capabilities']:
                    analysis['new_capabilities'].append('reinforcement_learning')
                    self.capability_index['capabilities']['reinforcement_learning'] = {
                        'source': str(file),
                        'first_detected': datetime.now().isoformat()
                    }
        
        return analysis

    def generate_app_blueprint(self, requirements: Dict) -> Dict:
        """Generate a new app blueprint based on requirements and known capabilities"""
        blueprint = {
            'app_id': hashlib.sha256(datetime.now().isoformat().encode()).hexdigest(),
            'requirements': requirements,
            'components': [],
            'estimated_complexity': 0,
            'capabilities_required': []
        }
        
        # Match requirements to known capabilities
        if 'neural' in requirements.get('type', '').lower():
            if 'neural_network' in self.capability_index['capabilities']:
                blueprint['components'].append({
                    'type': 'neural_network',
                    'source': self.capability_index['capabilities']['neural_network']['source'],
                    'implementation_path': None
                })
                blueprint['capabilities_required'].append('neural_network')
                blueprint['estimated_complexity'] += 5
        
        # Add common infrastructure components
        blueprint['components'].extend([
            {
                'type': 'data_pipeline',
                'source': 'internal',
                'implementation_path': None
            },
            {
                'type': 'user_interface',
                'source': 'internal',
                'implementation_path': None
            }
        ])
        
        return blueprint

    def build_app(self, blueprint: Dict) -> Dict:
        """Execute the app building process"""
        build_report = {
            'app_id': blueprint['app_id'],
            'steps': [],
            'success': False,
            'generated_files': []
        }
        
        app_dir = self.app_factory_dir / blueprint['app_id']
        app_dir.mkdir(exist_ok=True)
        
        # Create basic structure
        (app_dir / "src").mkdir()
        (app_dir / "tests").mkdir()
        
        # Generate main application file
        main_file = app_dir / "src" / "main.py"
        with open(main_file, 'w') as f:
            f.write("# Auto-generated AGI application\n\n")
            f.write("def main():\n")
            f.write("    print('AGI application running')\n")
            f.write("\nif __name__ == '__main__':\n")
            f.write("    main()\n")
        
        build_report['generated_files'].append(str(main_file))
        build_report['steps'].append('created_main_file')
        
        # Mark as successfully built (simplified for example)
        build_report['success'] = True
        return build_report

    def run_health_check(self) -> Dict:
        """Perform system health diagnostics"""
        self.system_health['memory_usage'] = self._get_memory_usage()
        self.system_health['component_status'] = {
            'knowledge_db': os.path.exists(self.knowledge_db),
            'app_factory': os.path.exists(self.app_factory_dir),
            'github_connection': self._test_github_connection()
        }
        return self.system_health

    def _get_memory_usage(self) -> Dict:
        """Calculate memory usage statistics"""
        total_size = 0
        for dirpath, _, filenames in os.walk(self.bulk_memory_root):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                total_size += os.path.getsize(fp)
        return {
            'total_bytes': total_size,
            'human_readable': f"{total_size / (1024**3):.2f} GB"
        }

    def _test_github_connection(self) -> bool:
        """Test connectivity to GitHub"""
        try:
            subprocess.run(['git', 'ls-remote', 'https://github.com'], 
                          timeout=10, check=True)
            return True
        except:
            return False