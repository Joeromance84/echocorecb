import time
import json
import traceback
import heapq
from collections import deque
from typing import Dict, Any, Callable, Optional, List, Tuple


class SelfHealingResonantEngine:
    """
    Self-healing, resonance-aware engine.
    Lifecycle:
      - Queues tasks with retries
      - On failure: retry with exponential backoff
      - When retries exhausted: transmutes into new guarded task
      - Grounds tasks if max transmutations exceeded
      - Logs lineage, bounded history, and exposes hooks
    """

    def __init__(
        self,
        name: str,
        max_concurrent: int = 5,
        default_retries: int = 1,
        max_transmutes_per_original: int = 2,
        base_backoff_seconds: float = 0.1,
        on_transmute: Optional[Callable[[Dict[str, Any], Dict[str, Any]], None]] = None,
        history_limit: int = 500,
    ):
        self.name = name
        self.max_concurrent = max_concurrent
        self.default_retries = default_retries
        self.max_transmutes_per_original = max_transmutes_per_original
        self.base_backoff_seconds = base_backoff_seconds
        self.on_transmute = on_transmute

        # Priority queue: (priority, uid, task_dict)
        self.queue: List[Tuple[int, int, Dict[str, Any]]] = []

        # Rolling history to avoid unbounded growth
        self.completed = deque(maxlen=history_limit)
        self.failed = deque(maxlen=history_limit)
        self.transmuted = deque(maxlen=history_limit)

        # Counters / state
        self.status = "idle"
        self.transmute_counts: Dict[str, int] = {}
        self._uid_counter = 0

        print(f"[INIT] Engine '{self.name}' initialized.")

    def _next_uid(self) -> int:
        """Unique increasing ID for task ordering."""
        self._uid_counter += 1
        return self._uid_counter

    def add_task(
        self,
        task_id: str,
        task_data: Dict[str, Any],
        task_fn: Callable,
        retries: Optional[int] = None,
        priority: int = 0,
    ):
        """Add a task to the queue."""
        task = {
            "id": task_id,
            "data": dict(task_data),
            "fn": task_fn,
            "status": "queued",
            "timestamp": time.time(),
            "retries_left": retries if retries is not None else self.default_retries,
            "original_id": task_id,
            "transmute_count": 0,
            "priority": priority,
        }
        heapq.heappush(self.queue, (priority, self._next_uid(), task))
        self.status = "processing"
        print(f"[QUEUE] Task '{task_id}' enqueued (priority={priority}, retries={task['retries_left']}).")

    def _calc_backoff(self, retries_consumed: int) -> float:
        """Exponential backoff: base * 2^n."""
        return self.base_backoff_seconds * (2 ** retries_consumed)

    def process(self):
        """Main synchronous loop."""
        while self.queue:
            batch = [heapq.heappop(self.queue) for _ in range(min(len(self.queue), self.max_concurrent))]
            print(f"[PROCESS] Batch size={len(batch)}")

            for _, _, task in batch:
                task["status"] = "in_progress"
                try:
                    print(f"[RUN] Executing task '{task['id']}'...")
                    result = task["fn"](task["data"])
                    task["status"] = "completed"
                    task["result"] = result
                    self.completed.append(task)
                    print(f"[SUCCESS] '{task['id']}' completed.")

                except Exception as e:
                    tb = traceback.format_exc()
                    task["status"] = "failed"
                    task["error"] = str(e)
                    task["traceback"] = tb
                    orig = task.get("original_id", task["id"])
                    self.transmute_counts.setdefault(orig, 0)

                    # Retry handling
                    if task.get("retries_left", 0) > 0:
                        retries_consumed = self.default_retries - task["retries_left"] + 1
                        task["retries_left"] -= 1
                        delay = self._calc_backoff(retries_consumed)
                        print(f"[RETRY] '{task['id']}' failed ({e}). Retrying after {delay:.2f}s...")
                        time.sleep(delay)
                        heapq.heappush(self.queue, (task["priority"], self._next_uid(), task))
                        continue

                    # Transmute handling
                    if self.transmute_counts[orig] < self.max_transmutes_per_original:
                        self._transmute_failure(task)
                        self.transmute_counts[orig] += 1
                    else:
                        task["resonance"] = "grounded"
                        self.failed.append(task)
                        print(f"[GROUND] '{task['id']}' grounded (max transmutes reached).")

        self.status = "idle"
        print(f"[DONE] Engine '{self.name}' finished.")

    def _transmute_failure(self, failed_task: Dict[str, Any]):
        """Convert failure into new guarded task."""
        orig_id = failed_task.get("original_id", failed_task["id"])
        exception_obj = self._get_exception_from_string(failed_task.get("error", ""))
        analysis = self._analyze_exception(exception_obj, failed_task.get("traceback", ""))

        new_task_id = f"{orig_id}-transmuted-{self._next_uid()}"
        new_data = dict(failed_task.get("data", {}))
        new_data["fix_applied"] = analysis.get("fix")
        new_data["_transmute_meta"] = {
            "reason": analysis.get("reason"),
            "timestamp": time.time(),
            "previous_error": failed_task.get("error"),
            "round": self.transmute_counts.get(orig_id, 0) + 1,
        }

        def guarded_fn(data):
            # Policy-based guards
            if "nonzero_guard" in analysis.get("policy_flags", []):
                if data.get("param_value", 0) == 0:
                    safe_val = analysis.get("safe_defaults", {}).get("param_value", 1)
                    data["param_value"] = safe_val
                    print(f"[GUARD] '{new_task_id}' applied nonzero_guard → {safe_val}")
            if "reparameterize" in analysis.get("policy_flags", []):
                data.setdefault("tuning", {})
                data["tuning"]["reparam"] = True
                print(f"[GUARD] '{new_task_id}' applied reparameterize.")

            return failed_task["fn"](data)

        new_task = {
            "id": new_task_id,
            "data": new_data,
            "fn": guarded_fn,
            "status": "transmuted",
            "timestamp": time.time(),
            "original_id": orig_id,
            "priority": failed_task.get("priority", 0),
            "retries_left": self.default_retries,
            "transmute_count": self.transmute_counts.get(orig_id, 0) + 1,
        }

        heapq.heappush(self.queue, (new_task["priority"], self._next_uid(), new_task))
        self.transmuted.append(new_task)
        self.failed.append(failed_task)

        print(f"[TRANSMUTE] '{failed_task['id']}' → '{new_task_id}' (fix={analysis.get('fix')})")

        if self.on_transmute:
            try:
                self.on_transmute(failed_task, new_task)
            except Exception as cb_e:
                print(f"[HOOK-ERR] on_transmute failed: {cb_e}")

        time.sleep(self.base_backoff_seconds)

    def _get_exception_from_string(self, err_str: str) -> Optional[Exception]:
        """Best-effort classification."""
        if not err_str:
            return None
        s = err_str.lower()
        if "division" in s:
            return ZeroDivisionError(s)
        if "runtime" in s:
            return RuntimeError(s)
        return Exception(s)

    def _analyze_exception(self, exc: Optional[Exception], tb: str) -> Dict[str, Any]:
        """Rule-based fix suggestions."""
        if exc is None:
            return {"fix": "general reparam", "reason": "unknown", "policy_flags": ["reparameterize"]}
        if isinstance(exc, ZeroDivisionError):
            return {
                "fix": "guard denominator nonzero",
                "reason": "division_by_zero",
                "policy_flags": ["nonzero_guard"],
                "safe_defaults": {"param_value": 1},
            }
        if isinstance(exc, RuntimeError):
            return {"fix": "adjust runtime params", "reason": "runtime_error", "policy_flags": ["reparameterize"]}
        return {"fix": "generic adjustments", "reason": "generic", "policy_flags": ["reparameterize"]}

    def get_status(self) -> Dict[str, Any]:
        """Engine status snapshot."""
        return {
            "engine": self.name,
            "status": self.status,
            "queue": len(self.queue),
            "completed": len(self.completed),
            "failed": len(self.failed),
            "transmuted": len(self.transmuted),
            "last_completed": self.completed[-1]["id"] if self.completed else None,
        }


# --- Example usage ---
def resilient_task(data: Dict[str, Any]) -> str:
    if data.get("fail_on_start"):
        raise RuntimeError("Initial failure")
    if data.get("fail_on_param") and data.get("param_value") == 0:
        raise ZeroDivisionError("Division by zero")
    time.sleep(data.get("duration", 0.01))
    return f"Processed: {data.get('message', 'No message')}"


if __name__ == "__main__":
    engine = SelfHealingResonantEngine("Adaptive_AI_Core", default_retries=1, max_transmutes_per_original=2)

    engine.add_task("t_fail", {"message": "will fail", "fail_on_start": True}, resilient_task)
    engine.add_task("t_math", {"message": "compute ratios", "fail_on_param": True, "param_value": 0}, resilient_task)
    engine.add_task("t_ok", {"message": "normal task", "duration": 0.02}, resilient_task)

    engine.process()

    print("\n--- Engine Report ---")
    print(json.dumps(engine.get_status(), indent=2))
